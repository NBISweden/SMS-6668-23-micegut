{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: nf-core/mag troubleshooting\n",
    "author: John Sundh\n",
    "date: last-modified\n",
    "format:\n",
    "    confluence-html:\n",
    "        code-fold: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**\n",
    "\n",
    "This notebook describes my attempts to run the nf-core/mag pipeline for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up nf-core/mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I looked into using the [nf-core/mag](https://nf-co.re/mag) Nextflow pipeline for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I installed a conda environment specifically to use with nf-core/mag using:\n",
    "\n",
    "```bash\n",
    "export CONDARC=\"/proj/snic2020-5-486/nobackup/SMS-23-6668-micegut/.condarc\"\n",
    "mamba env create -f mag-env.yml -p envs/mag\n",
    "mamba activate envs/mag\n",
    "# Copy scripts to set and unset environment variables\n",
    "mkdir -p $CONDA_PREFIX/etc/conda/deactivate.d $CONDA_PREFIX/etc/conda/activate.d\n",
    "cp src/activate.d/env_vars.sh $CONDA_PREFIX/etc/conda/activate.d/\n",
    "cp src/deactivate.d/env_vars.sh $CONDA_PREFIX/etc/conda/deactivate.d/\n",
    "# Re-activate the environment\n",
    "mamba activate envs/mag\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, after some trial runs I found that the pipline is likely not suited for this analysis. This could also be due to my lack of detailed knowledge and experience with debugging Nextflow pipelines but nevertheless I turned to other alternatives. See below for my attempts at troubleshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some issues with the nf-core/mag pipeline that become apparent when trying to use on a large dataset with several co-assemblies. Using the setup specified here with 108 samples divided into 10 assembly groups and specifying `--binning_map_mode all` results in 108 x 10 = 1080 bam files. With each bam file ~Â 3-4 G in size that comes to 3.2 - 4.2 TB of data.\n",
    "\n",
    "If assemblies could be created and binned one at a time that would allow temporary bam files to be cleaned up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I tried to run the full pipeline as a node job after a tip from Phil Ewels (nf-core developer). In theory that would allow the pipeline to use local node storage for the work directory, after which only the finished results could be copied to the project folder. \n",
    "\n",
    "However this resulted in failed runs with no apparent output in either the nextflow log or slurm logs. Also there are obvious caveats to this as the work directory cannot be saved in intermediate states if the pipeline fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead I tried to use group-specific input files where there'd be one sample list per assembly group. For example the 'mock' sample list would contain all samples but there would only be group assignments for the 'mock' group. The plan was to run the pipeline 10 times, once for each sample list. \n",
    "\n",
    "However, it appears the pipeline tries to create an assembly also for the unassigned group which obviously fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next strategy was to try and first generate the co-assemblies using a params file where `--skip_binning` is set to true. That would run only the QC + Assembly steps which would only generate ~350 G of storage for the QCd reads + a few additional G for each assembly.\n",
    "\n",
    "Then using another params file where all samples are assigned to the already assembled group and specifying `--binning_map_mode all` maybe the pipeline would use the assembly as-is but map all samples to it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to run assembly for the 'mock' group:\n",
    "\n",
    "```bash\n",
    "nextflow run -c conf/custom.config -params-file conf/mag.assembly.yml nf-core/mag -r 2.3.0 -resume -profile uppmax --project snic2022-5-350 --input data/sample_list.mock-assemble.csv\n",
    "```\n",
    "\n",
    "Then to run binning for the same group:\n",
    "\n",
    "```bash\n",
    "nextflow run -c conf/custom.config -params-file conf/mag.binning.yml nf-core/mag -r 2.3.0 -resume -profile uppmax --project snic2022-5-350 --input data/sample_list.mock-binning.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this doesn't work either because the assembly is re-generated with all the samples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jupyter] *",
   "language": "python",
   "name": "conda-env-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
